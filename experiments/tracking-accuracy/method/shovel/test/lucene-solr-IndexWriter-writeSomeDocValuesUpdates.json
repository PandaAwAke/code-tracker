{
  "origin": "codeshovel",
  "repositoryName": "lucene-solr",
  "repositoryPath": "H:\\Projects\\apache\\lucene-solr/.git",
  "startCommitName": "38bf976cd4b9e324c21664bd7ae3d554df803705",
  "sourceFileName": "IndexWriter.java",
  "functionName": "writeSomeDocValuesUpdates",
  "functionId": "writeSomeDocValuesUpdates",
  "sourceFilePath": "lucene/core/src/java/org/apache/lucene/index/IndexWriter.java",
  "functionStartLine": 579,
  "functionEndLine": 637,
  "numCommitsSeen": 359,
  "timeTaken": 5086,
  "changeHistory": [
    "772e171ac6e70c96295f65749d0d15339133b8a6",
    "61e68ec1e8cd409cb51a209f827fc64710b31f6f",
    "8975692953713923bd1cc67766cf92565183c2b8",
    "acb3c379427193036f3d56503529400736ac5dff",
    "58105a203a19d18a56e09cf69dc0083c1b890315"
  ],
  "changeHistoryShort": {
    "772e171ac6e70c96295f65749d0d15339133b8a6": "Ybodychange",
    "61e68ec1e8cd409cb51a209f827fc64710b31f6f": "Ybodychange",
    "8975692953713923bd1cc67766cf92565183c2b8": "Ybodychange",
    "acb3c379427193036f3d56503529400736ac5dff": "Ybodychange",
    "58105a203a19d18a56e09cf69dc0083c1b890315": "Yintroduced"
  },
  "changeHistoryDetails": {
    "772e171ac6e70c96295f65749d0d15339133b8a6": {
      "type": "Ybodychange",
      "commitMessage": "LUCENE-8358: Relax assertion in IW#writeSomeDocValuesUpdates\n\nThis assertion is too strict since we can see this situation if for instance\na ReadersAndUpdates instance gets written to disk concurrently and\nreaderpooling is off. This change also simplifies ReaderPool#getReadersByRam and\nadds a test for it.\n",
      "commitDate": "2018-06-15, 6:01 a.m.",
      "commitName": "772e171ac6e70c96295f65749d0d15339133b8a6",
      "commitAuthor": "Simon Willnauer",
      "commitDateOld": "2018-06-13, 4:10 a.m.",
      "commitNameOld": "61e68ec1e8cd409cb51a209f827fc64710b31f6f",
      "commitAuthorOld": "Simon Willnauer",
      "daysBetweenCommits": 2.08,
      "commitsBetweenForRepo": 19,
      "commitsBetweenForFile": 1,
      "actualSource": "  void writeSomeDocValuesUpdates() throws IOException {\n    if (writeDocValuesLock.compareAndSet(false, true)) {\n      try {\n        final double ramBufferSizeMB \u003d config.getRAMBufferSizeMB();\n        // If the reader pool is \u003e 50% of our IW buffer, then write the updates:\n        if (ramBufferSizeMB !\u003d IndexWriterConfig.DISABLE_AUTO_FLUSH) {\n          long startNS \u003d System.nanoTime();\n\n          long ramBytesUsed \u003d getReaderPoolRamBytesUsed();\n          if (ramBytesUsed \u003e 0.5 * ramBufferSizeMB * 1024 * 1024) {\n            if (infoStream.isEnabled(\"BD\")) {\n              infoStream.message(\"BD\", String.format(Locale.ROOT, \"now write some pending DV updates: %.2f MB used vs IWC Buffer %.2f MB\",\n                  ramBytesUsed/1024./1024., ramBufferSizeMB));\n            }\n\n            // Sort by largest ramBytesUsed:\n            final List\u003cReadersAndUpdates\u003e list \u003d readerPool.getReadersByRam();\n            int count \u003d 0;\n            for (ReadersAndUpdates rld : list) {\n\n              if (ramBytesUsed \u003c\u003d 0.5 * ramBufferSizeMB * 1024 * 1024) {\n                break;\n              }\n              // We need to do before/after because not all RAM in this RAU is used by DV updates, and\n              // not all of those bytes can be written here:\n              long bytesUsedBefore \u003d rld.ramBytesUsed.get();\n              if (bytesUsedBefore \u003d\u003d 0) {\n                continue; // nothing to do here - lets not acquire the lock\n              }\n              // Only acquire IW lock on each write, since this is a time consuming operation.  This way\n              // other threads get a chance to run in between our writes.\n              synchronized (this) {\n                // It\u0027s possible that the segment of a reader returned by readerPool#getReadersByRam\n                // is dropped before being processed here. If it happens, we need to skip that reader.\n                // this is also best effort to free ram, there might be some other thread writing this rld concurrently\n                // which wins and then if readerPooling is off this rld will be dropped.\n                if (readerPool.get(rld.info, false) \u003d\u003d null) {\n                  continue;\n                }\n                if (rld.writeFieldUpdates(directory, globalFieldNumberMap, bufferedUpdatesStream.getCompletedDelGen(), infoStream)) {\n                  checkpointNoSIS();\n                }\n              }\n              long bytesUsedAfter \u003d rld.ramBytesUsed.get();\n              ramBytesUsed -\u003d bytesUsedBefore - bytesUsedAfter;\n              count++;\n            }\n\n            if (infoStream.isEnabled(\"BD\")) {\n              infoStream.message(\"BD\", String.format(Locale.ROOT, \"done write some DV updates for %d segments: now %.2f MB used vs IWC Buffer %.2f MB; took %.2f sec\",\n                  count, getReaderPoolRamBytesUsed()/1024./1024., ramBufferSizeMB, ((System.nanoTime() - startNS)/1000000000.)));\n            }\n          }\n        }\n      } finally {\n        writeDocValuesLock.set(false);\n      }\n    }\n  }",
      "path": "lucene/core/src/java/org/apache/lucene/index/IndexWriter.java",
      "functionStartLine": 578,
      "functionName": "writeSomeDocValuesUpdates",
      "diff": "@@ -1,57 +1,59 @@\n   void writeSomeDocValuesUpdates() throws IOException {\n     if (writeDocValuesLock.compareAndSet(false, true)) {\n       try {\n         final double ramBufferSizeMB \u003d config.getRAMBufferSizeMB();\n         // If the reader pool is \u003e 50% of our IW buffer, then write the updates:\n         if (ramBufferSizeMB !\u003d IndexWriterConfig.DISABLE_AUTO_FLUSH) {\n           long startNS \u003d System.nanoTime();\n \n           long ramBytesUsed \u003d getReaderPoolRamBytesUsed();\n           if (ramBytesUsed \u003e 0.5 * ramBufferSizeMB * 1024 * 1024) {\n             if (infoStream.isEnabled(\"BD\")) {\n               infoStream.message(\"BD\", String.format(Locale.ROOT, \"now write some pending DV updates: %.2f MB used vs IWC Buffer %.2f MB\",\n                   ramBytesUsed/1024./1024., ramBufferSizeMB));\n             }\n \n             // Sort by largest ramBytesUsed:\n-            PriorityQueue\u003cReadersAndUpdates\u003e queue \u003d readerPool.getReadersByRam();\n+            final List\u003cReadersAndUpdates\u003e list \u003d readerPool.getReadersByRam();\n             int count \u003d 0;\n-            while (ramBytesUsed \u003e 0.5 * ramBufferSizeMB * 1024 * 1024) {\n-              ReadersAndUpdates rld \u003d queue.poll();\n-              if (rld \u003d\u003d null) {\n+            for (ReadersAndUpdates rld : list) {\n+\n+              if (ramBytesUsed \u003c\u003d 0.5 * ramBufferSizeMB * 1024 * 1024) {\n                 break;\n               }\n-\n               // We need to do before/after because not all RAM in this RAU is used by DV updates, and\n               // not all of those bytes can be written here:\n               long bytesUsedBefore \u003d rld.ramBytesUsed.get();\n-\n+              if (bytesUsedBefore \u003d\u003d 0) {\n+                continue; // nothing to do here - lets not acquire the lock\n+              }\n               // Only acquire IW lock on each write, since this is a time consuming operation.  This way\n               // other threads get a chance to run in between our writes.\n               synchronized (this) {\n                 // It\u0027s possible that the segment of a reader returned by readerPool#getReadersByRam\n                 // is dropped before being processed here. If it happens, we need to skip that reader.\n+                // this is also best effort to free ram, there might be some other thread writing this rld concurrently\n+                // which wins and then if readerPooling is off this rld will be dropped.\n                 if (readerPool.get(rld.info, false) \u003d\u003d null) {\n-                  assert segmentInfos.contains(rld.info) \u003d\u003d false : \"Segment [\" + rld.info + \"] is not dropped yet\";\n                   continue;\n                 }\n                 if (rld.writeFieldUpdates(directory, globalFieldNumberMap, bufferedUpdatesStream.getCompletedDelGen(), infoStream)) {\n                   checkpointNoSIS();\n                 }\n               }\n               long bytesUsedAfter \u003d rld.ramBytesUsed.get();\n               ramBytesUsed -\u003d bytesUsedBefore - bytesUsedAfter;\n               count++;\n             }\n \n             if (infoStream.isEnabled(\"BD\")) {\n               infoStream.message(\"BD\", String.format(Locale.ROOT, \"done write some DV updates for %d segments: now %.2f MB used vs IWC Buffer %.2f MB; took %.2f sec\",\n                   count, getReaderPoolRamBytesUsed()/1024./1024., ramBufferSizeMB, ((System.nanoTime() - startNS)/1000000000.)));\n             }\n           }\n         }\n       } finally {\n         writeDocValuesLock.set(false);\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "extendedDetails": {}
    },
    "61e68ec1e8cd409cb51a209f827fc64710b31f6f": {
      "type": "Ybodychange",
      "commitMessage": "LUCENE-8355: Prevent IW from opening an already dropped segment while DV updates are written\n\nThis change fixes an isse where IW asks ReadersAndUpdates to write a DV updates for a\nsegment that has been dropped concurrently. The race only occurs if ram buffers are filled\nup enough to trigger flushing DV to disk.\n\nCo-authored-by: Nhat Nguyen \u003cnhat.nguyen@elastic.co\u003e\n",
      "commitDate": "2018-06-13, 4:10 a.m.",
      "commitName": "61e68ec1e8cd409cb51a209f827fc64710b31f6f",
      "commitAuthor": "Simon Willnauer",
      "commitDateOld": "2018-06-04, 9:05 a.m.",
      "commitNameOld": "fe83838ec3768f25964a04510cd10772cf034d34",
      "commitAuthorOld": "Simon Willnauer",
      "daysBetweenCommits": 8.8,
      "commitsBetweenForRepo": 75,
      "commitsBetweenForFile": 1,
      "actualSource": "  void writeSomeDocValuesUpdates() throws IOException {\n    if (writeDocValuesLock.compareAndSet(false, true)) {\n      try {\n        final double ramBufferSizeMB \u003d config.getRAMBufferSizeMB();\n        // If the reader pool is \u003e 50% of our IW buffer, then write the updates:\n        if (ramBufferSizeMB !\u003d IndexWriterConfig.DISABLE_AUTO_FLUSH) {\n          long startNS \u003d System.nanoTime();\n\n          long ramBytesUsed \u003d getReaderPoolRamBytesUsed();\n          if (ramBytesUsed \u003e 0.5 * ramBufferSizeMB * 1024 * 1024) {\n            if (infoStream.isEnabled(\"BD\")) {\n              infoStream.message(\"BD\", String.format(Locale.ROOT, \"now write some pending DV updates: %.2f MB used vs IWC Buffer %.2f MB\",\n                  ramBytesUsed/1024./1024., ramBufferSizeMB));\n            }\n\n            // Sort by largest ramBytesUsed:\n            PriorityQueue\u003cReadersAndUpdates\u003e queue \u003d readerPool.getReadersByRam();\n            int count \u003d 0;\n            while (ramBytesUsed \u003e 0.5 * ramBufferSizeMB * 1024 * 1024) {\n              ReadersAndUpdates rld \u003d queue.poll();\n              if (rld \u003d\u003d null) {\n                break;\n              }\n\n              // We need to do before/after because not all RAM in this RAU is used by DV updates, and\n              // not all of those bytes can be written here:\n              long bytesUsedBefore \u003d rld.ramBytesUsed.get();\n\n              // Only acquire IW lock on each write, since this is a time consuming operation.  This way\n              // other threads get a chance to run in between our writes.\n              synchronized (this) {\n                // It\u0027s possible that the segment of a reader returned by readerPool#getReadersByRam\n                // is dropped before being processed here. If it happens, we need to skip that reader.\n                if (readerPool.get(rld.info, false) \u003d\u003d null) {\n                  assert segmentInfos.contains(rld.info) \u003d\u003d false : \"Segment [\" + rld.info + \"] is not dropped yet\";\n                  continue;\n                }\n                if (rld.writeFieldUpdates(directory, globalFieldNumberMap, bufferedUpdatesStream.getCompletedDelGen(), infoStream)) {\n                  checkpointNoSIS();\n                }\n              }\n              long bytesUsedAfter \u003d rld.ramBytesUsed.get();\n              ramBytesUsed -\u003d bytesUsedBefore - bytesUsedAfter;\n              count++;\n            }\n\n            if (infoStream.isEnabled(\"BD\")) {\n              infoStream.message(\"BD\", String.format(Locale.ROOT, \"done write some DV updates for %d segments: now %.2f MB used vs IWC Buffer %.2f MB; took %.2f sec\",\n                  count, getReaderPoolRamBytesUsed()/1024./1024., ramBufferSizeMB, ((System.nanoTime() - startNS)/1000000000.)));\n            }\n          }\n        }\n      } finally {\n        writeDocValuesLock.set(false);\n      }\n    }\n  }",
      "path": "lucene/core/src/java/org/apache/lucene/index/IndexWriter.java",
      "functionStartLine": 579,
      "functionName": "writeSomeDocValuesUpdates",
      "diff": "@@ -1,51 +1,57 @@\n   void writeSomeDocValuesUpdates() throws IOException {\n     if (writeDocValuesLock.compareAndSet(false, true)) {\n       try {\n         final double ramBufferSizeMB \u003d config.getRAMBufferSizeMB();\n         // If the reader pool is \u003e 50% of our IW buffer, then write the updates:\n         if (ramBufferSizeMB !\u003d IndexWriterConfig.DISABLE_AUTO_FLUSH) {\n           long startNS \u003d System.nanoTime();\n \n           long ramBytesUsed \u003d getReaderPoolRamBytesUsed();\n           if (ramBytesUsed \u003e 0.5 * ramBufferSizeMB * 1024 * 1024) {\n             if (infoStream.isEnabled(\"BD\")) {\n               infoStream.message(\"BD\", String.format(Locale.ROOT, \"now write some pending DV updates: %.2f MB used vs IWC Buffer %.2f MB\",\n                   ramBytesUsed/1024./1024., ramBufferSizeMB));\n             }\n \n             // Sort by largest ramBytesUsed:\n             PriorityQueue\u003cReadersAndUpdates\u003e queue \u003d readerPool.getReadersByRam();\n             int count \u003d 0;\n             while (ramBytesUsed \u003e 0.5 * ramBufferSizeMB * 1024 * 1024) {\n               ReadersAndUpdates rld \u003d queue.poll();\n               if (rld \u003d\u003d null) {\n                 break;\n               }\n \n               // We need to do before/after because not all RAM in this RAU is used by DV updates, and\n               // not all of those bytes can be written here:\n               long bytesUsedBefore \u003d rld.ramBytesUsed.get();\n \n               // Only acquire IW lock on each write, since this is a time consuming operation.  This way\n               // other threads get a chance to run in between our writes.\n               synchronized (this) {\n+                // It\u0027s possible that the segment of a reader returned by readerPool#getReadersByRam\n+                // is dropped before being processed here. If it happens, we need to skip that reader.\n+                if (readerPool.get(rld.info, false) \u003d\u003d null) {\n+                  assert segmentInfos.contains(rld.info) \u003d\u003d false : \"Segment [\" + rld.info + \"] is not dropped yet\";\n+                  continue;\n+                }\n                 if (rld.writeFieldUpdates(directory, globalFieldNumberMap, bufferedUpdatesStream.getCompletedDelGen(), infoStream)) {\n                   checkpointNoSIS();\n                 }\n               }\n               long bytesUsedAfter \u003d rld.ramBytesUsed.get();\n               ramBytesUsed -\u003d bytesUsedBefore - bytesUsedAfter;\n               count++;\n             }\n \n             if (infoStream.isEnabled(\"BD\")) {\n               infoStream.message(\"BD\", String.format(Locale.ROOT, \"done write some DV updates for %d segments: now %.2f MB used vs IWC Buffer %.2f MB; took %.2f sec\",\n                   count, getReaderPoolRamBytesUsed()/1024./1024., ramBufferSizeMB, ((System.nanoTime() - startNS)/1000000000.)));\n             }\n           }\n         }\n       } finally {\n         writeDocValuesLock.set(false);\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "extendedDetails": {}
    },
    "8975692953713923bd1cc67766cf92565183c2b8": {
      "type": "Ybodychange",
      "commitMessage": "LUCENE-8260: Extract ReaderPool from IndexWriter\n\nReaderPool plays a central role in the IndexWriter pooling NRT readers\r\nand making sure we write buffered deletes and updates to disk. This class\r\nused to be a non-static inner class accessing many aspects including locks\r\nfrom the IndexWriter itself. This change moves the class outside of IW and\r\ndefines it\u0027s responsibility in a clear way with respect to locks etc. Now\r\nIndexWriter doesn\u0027t need to share ReaderPool anymore and reacts on writes done\r\ninside the pool by checkpointing internally. This also removes acquiring the IW\r\nlock inside the reader pool which makes reasoning about concurrency difficult.\r\n\r\nThis change also add javadocs and dedicated tests for the ReaderPool class.\r\n",
      "commitDate": "2018-04-23, 4:29 a.m.",
      "commitName": "8975692953713923bd1cc67766cf92565183c2b8",
      "commitAuthor": "Simon Willnauer",
      "commitDateOld": "2018-04-17, 10:26 a.m.",
      "commitNameOld": "d904112428184ce9c1726313add5d184f4014a72",
      "commitAuthorOld": "Simon Willnauer",
      "daysBetweenCommits": 5.75,
      "commitsBetweenForRepo": 31,
      "commitsBetweenForFile": 1,
      "actualSource": "  void writeSomeDocValuesUpdates() throws IOException {\n    if (writeDocValuesLock.compareAndSet(false, true)) {\n      try {\n        final double ramBufferSizeMB \u003d config.getRAMBufferSizeMB();\n        // If the reader pool is \u003e 50% of our IW buffer, then write the updates:\n        if (ramBufferSizeMB !\u003d IndexWriterConfig.DISABLE_AUTO_FLUSH) {\n          long startNS \u003d System.nanoTime();\n\n          long ramBytesUsed \u003d getReaderPoolRamBytesUsed();\n          if (ramBytesUsed \u003e 0.5 * ramBufferSizeMB * 1024 * 1024) {\n            if (infoStream.isEnabled(\"BD\")) {\n              infoStream.message(\"BD\", String.format(Locale.ROOT, \"now write some pending DV updates: %.2f MB used vs IWC Buffer %.2f MB\",\n                  ramBytesUsed/1024./1024., ramBufferSizeMB));\n            }\n\n            // Sort by largest ramBytesUsed:\n            PriorityQueue\u003cReadersAndUpdates\u003e queue \u003d readerPool.getReadersByRam();\n            int count \u003d 0;\n            while (ramBytesUsed \u003e 0.5 * ramBufferSizeMB * 1024 * 1024) {\n              ReadersAndUpdates rld \u003d queue.poll();\n              if (rld \u003d\u003d null) {\n                break;\n              }\n\n              // We need to do before/after because not all RAM in this RAU is used by DV updates, and\n              // not all of those bytes can be written here:\n              long bytesUsedBefore \u003d rld.ramBytesUsed.get();\n\n              // Only acquire IW lock on each write, since this is a time consuming operation.  This way\n              // other threads get a chance to run in between our writes.\n              synchronized (this) {\n                if (rld.writeFieldUpdates(directory, globalFieldNumberMap, bufferedUpdatesStream.getCompletedDelGen(), infoStream)) {\n                  checkpointNoSIS();\n                }\n              }\n              long bytesUsedAfter \u003d rld.ramBytesUsed.get();\n              ramBytesUsed -\u003d bytesUsedBefore - bytesUsedAfter;\n              count++;\n            }\n\n            if (infoStream.isEnabled(\"BD\")) {\n              infoStream.message(\"BD\", String.format(Locale.ROOT, \"done write some DV updates for %d segments: now %.2f MB used vs IWC Buffer %.2f MB; took %.2f sec\",\n                  count, getReaderPoolRamBytesUsed()/1024./1024., ramBufferSizeMB, ((System.nanoTime() - startNS)/1000000000.)));\n            }\n          }\n        }\n      } finally {\n        writeDocValuesLock.set(false);\n      }\n    }\n  }",
      "path": "lucene/core/src/java/org/apache/lucene/index/IndexWriter.java",
      "functionStartLine": 537,
      "functionName": "writeSomeDocValuesUpdates",
      "diff": "@@ -1,62 +1,51 @@\n-    void writeSomeDocValuesUpdates() throws IOException {\n+  void writeSomeDocValuesUpdates() throws IOException {\n+    if (writeDocValuesLock.compareAndSet(false, true)) {\n+      try {\n+        final double ramBufferSizeMB \u003d config.getRAMBufferSizeMB();\n+        // If the reader pool is \u003e 50% of our IW buffer, then write the updates:\n+        if (ramBufferSizeMB !\u003d IndexWriterConfig.DISABLE_AUTO_FLUSH) {\n+          long startNS \u003d System.nanoTime();\n \n-      assert Thread.holdsLock(IndexWriter.this) \u003d\u003d false;\n+          long ramBytesUsed \u003d getReaderPoolRamBytesUsed();\n+          if (ramBytesUsed \u003e 0.5 * ramBufferSizeMB * 1024 * 1024) {\n+            if (infoStream.isEnabled(\"BD\")) {\n+              infoStream.message(\"BD\", String.format(Locale.ROOT, \"now write some pending DV updates: %.2f MB used vs IWC Buffer %.2f MB\",\n+                  ramBytesUsed/1024./1024., ramBufferSizeMB));\n+            }\n \n-      if (writeDocValuesLock.compareAndSet(false, true)) {\n-        try {\n-\n-          LiveIndexWriterConfig config \u003d getConfig();\n-          double mb \u003d config.getRAMBufferSizeMB();\n-          // If the reader pool is \u003e 50% of our IW buffer, then write the updates:\n-          if (mb !\u003d IndexWriterConfig.DISABLE_AUTO_FLUSH) {\n-            long startNS \u003d System.nanoTime();\n-            \n-            long ramBytesUsed \u003d ramBytesUsed();\n-            if (ramBytesUsed \u003e 0.5 * mb * 1024 * 1024) {\n-              if (infoStream.isEnabled(\"BD\")) {\n-                infoStream.message(\"BD\", String.format(Locale.ROOT, \"now write some pending DV updates: %.2f MB used vs IWC Buffer %.2f MB\",\n-                                                       ramBytesUsed/1024./1024., mb));\n+            // Sort by largest ramBytesUsed:\n+            PriorityQueue\u003cReadersAndUpdates\u003e queue \u003d readerPool.getReadersByRam();\n+            int count \u003d 0;\n+            while (ramBytesUsed \u003e 0.5 * ramBufferSizeMB * 1024 * 1024) {\n+              ReadersAndUpdates rld \u003d queue.poll();\n+              if (rld \u003d\u003d null) {\n+                break;\n               }\n-          \n-              // Sort by largest ramBytesUsed:\n-              PriorityQueue\u003cReadersAndUpdates\u003e queue \u003d new PriorityQueue\u003c\u003e(readerMap.size(), (a, b) -\u003e Long.compare(b.ramBytesUsed.get(), a.ramBytesUsed.get()));\n+\n+              // We need to do before/after because not all RAM in this RAU is used by DV updates, and\n+              // not all of those bytes can be written here:\n+              long bytesUsedBefore \u003d rld.ramBytesUsed.get();\n+\n+              // Only acquire IW lock on each write, since this is a time consuming operation.  This way\n+              // other threads get a chance to run in between our writes.\n               synchronized (this) {\n-                for (ReadersAndUpdates rld : readerMap.values()) {\n-                  queue.add(rld);\n+                if (rld.writeFieldUpdates(directory, globalFieldNumberMap, bufferedUpdatesStream.getCompletedDelGen(), infoStream)) {\n+                  checkpointNoSIS();\n                 }\n               }\n+              long bytesUsedAfter \u003d rld.ramBytesUsed.get();\n+              ramBytesUsed -\u003d bytesUsedBefore - bytesUsedAfter;\n+              count++;\n+            }\n \n-              int count \u003d 0;\n-              while (ramBytesUsed \u003e 0.5 * mb * 1024 * 1024) {\n-                ReadersAndUpdates rld \u003d queue.poll();\n-                if (rld \u003d\u003d null) {\n-                  break;\n-                }\n-\n-                // We need to do before/after because not all RAM in this RAU is used by DV updates, and\n-                // not all of those bytes can be written here:\n-                long bytesUsedBefore \u003d rld.ramBytesUsed.get();\n-\n-                // Only acquire IW lock on each write, since this is a time consuming operation.  This way\n-                // other threads get a chance to run in between our writes.\n-                synchronized (IndexWriter.this) {\n-                  if (rld.writeFieldUpdates(directory, globalFieldNumberMap, bufferedUpdatesStream.getCompletedDelGen(), infoStream)) {\n-                    checkpointNoSIS();\n-                  }\n-                }\n-                long bytesUsedAfter \u003d rld.ramBytesUsed.get();\n-                ramBytesUsed -\u003d bytesUsedBefore - bytesUsedAfter;\n-                count++;\n-              }\n-\n-              if (infoStream.isEnabled(\"BD\")) {\n-                infoStream.message(\"BD\", String.format(Locale.ROOT, \"done write some DV updates for %d segments: now %.2f MB used vs IWC Buffer %.2f MB; took %.2f sec\",\n-                                                       count, ramBytesUsed()/1024./1024., mb, ((System.nanoTime() - startNS)/1000000000.)));\n-              }\n+            if (infoStream.isEnabled(\"BD\")) {\n+              infoStream.message(\"BD\", String.format(Locale.ROOT, \"done write some DV updates for %d segments: now %.2f MB used vs IWC Buffer %.2f MB; took %.2f sec\",\n+                  count, getReaderPoolRamBytesUsed()/1024./1024., ramBufferSizeMB, ((System.nanoTime() - startNS)/1000000000.)));\n             }\n           }\n-        } finally {\n-          writeDocValuesLock.set(false);\n         }\n+      } finally {\n+        writeDocValuesLock.set(false);\n       }\n-    }\n\\ No newline at end of file\n+    }\n+  }\n\\ No newline at end of file\n",
      "extendedDetails": {}
    },
    "acb3c379427193036f3d56503529400736ac5dff": {
      "type": "Ybodychange",
      "commitMessage": "LUCENE-8232: Separate out PendingDeletes from ReadersAndUpdates\n\nToday ReadersAndUpdates is tightly coupled with IW and all the\nhandling of pending deletes. This change decouples IW and pending\ndeletes from ReadersAndUpdates and makes PendingDeletes unittestable.\n",
      "commitDate": "2018-03-31, 4:25 a.m.",
      "commitName": "acb3c379427193036f3d56503529400736ac5dff",
      "commitAuthor": "Simon Willnauer",
      "commitDateOld": "2018-03-21, 4:41 a.m.",
      "commitNameOld": "d4e69c5cd868d0f5b71da0f4b23c2cd61d1b0ea0",
      "commitAuthorOld": "Simon Willnauer",
      "daysBetweenCommits": 9.99,
      "commitsBetweenForRepo": 81,
      "commitsBetweenForFile": 1,
      "actualSource": "    void writeSomeDocValuesUpdates() throws IOException {\n\n      assert Thread.holdsLock(IndexWriter.this) \u003d\u003d false;\n\n      if (writeDocValuesLock.compareAndSet(false, true)) {\n        try {\n\n          LiveIndexWriterConfig config \u003d getConfig();\n          double mb \u003d config.getRAMBufferSizeMB();\n          // If the reader pool is \u003e 50% of our IW buffer, then write the updates:\n          if (mb !\u003d IndexWriterConfig.DISABLE_AUTO_FLUSH) {\n            long startNS \u003d System.nanoTime();\n            \n            long ramBytesUsed \u003d ramBytesUsed();\n            if (ramBytesUsed \u003e 0.5 * mb * 1024 * 1024) {\n              if (infoStream.isEnabled(\"BD\")) {\n                infoStream.message(\"BD\", String.format(Locale.ROOT, \"now write some pending DV updates: %.2f MB used vs IWC Buffer %.2f MB\",\n                                                       ramBytesUsed/1024./1024., mb));\n              }\n          \n              // Sort by largest ramBytesUsed:\n              PriorityQueue\u003cReadersAndUpdates\u003e queue \u003d new PriorityQueue\u003c\u003e(readerMap.size(), (a, b) -\u003e Long.compare(b.ramBytesUsed.get(), a.ramBytesUsed.get()));\n              synchronized (this) {\n                for (ReadersAndUpdates rld : readerMap.values()) {\n                  queue.add(rld);\n                }\n              }\n\n              int count \u003d 0;\n              while (ramBytesUsed \u003e 0.5 * mb * 1024 * 1024) {\n                ReadersAndUpdates rld \u003d queue.poll();\n                if (rld \u003d\u003d null) {\n                  break;\n                }\n\n                // We need to do before/after because not all RAM in this RAU is used by DV updates, and\n                // not all of those bytes can be written here:\n                long bytesUsedBefore \u003d rld.ramBytesUsed.get();\n\n                // Only acquire IW lock on each write, since this is a time consuming operation.  This way\n                // other threads get a chance to run in between our writes.\n                synchronized (IndexWriter.this) {\n                  if (rld.writeFieldUpdates(directory, globalFieldNumberMap, bufferedUpdatesStream.getCompletedDelGen(), infoStream)) {\n                    checkpointNoSIS();\n                  }\n                }\n                long bytesUsedAfter \u003d rld.ramBytesUsed.get();\n                ramBytesUsed -\u003d bytesUsedBefore - bytesUsedAfter;\n                count++;\n              }\n\n              if (infoStream.isEnabled(\"BD\")) {\n                infoStream.message(\"BD\", String.format(Locale.ROOT, \"done write some DV updates for %d segments: now %.2f MB used vs IWC Buffer %.2f MB; took %.2f sec\",\n                                                       count, ramBytesUsed()/1024./1024., mb, ((System.nanoTime() - startNS)/1000000000.)));\n              }\n            }\n          }\n        } finally {\n          writeDocValuesLock.set(false);\n        }\n      }\n    }",
      "path": "lucene/core/src/java/org/apache/lucene/index/IndexWriter.java",
      "functionStartLine": 670,
      "functionName": "writeSomeDocValuesUpdates",
      "diff": "@@ -1,60 +1,62 @@\n     void writeSomeDocValuesUpdates() throws IOException {\n \n       assert Thread.holdsLock(IndexWriter.this) \u003d\u003d false;\n \n       if (writeDocValuesLock.compareAndSet(false, true)) {\n         try {\n \n           LiveIndexWriterConfig config \u003d getConfig();\n           double mb \u003d config.getRAMBufferSizeMB();\n           // If the reader pool is \u003e 50% of our IW buffer, then write the updates:\n           if (mb !\u003d IndexWriterConfig.DISABLE_AUTO_FLUSH) {\n             long startNS \u003d System.nanoTime();\n             \n             long ramBytesUsed \u003d ramBytesUsed();\n             if (ramBytesUsed \u003e 0.5 * mb * 1024 * 1024) {\n               if (infoStream.isEnabled(\"BD\")) {\n                 infoStream.message(\"BD\", String.format(Locale.ROOT, \"now write some pending DV updates: %.2f MB used vs IWC Buffer %.2f MB\",\n                                                        ramBytesUsed/1024./1024., mb));\n               }\n           \n               // Sort by largest ramBytesUsed:\n               PriorityQueue\u003cReadersAndUpdates\u003e queue \u003d new PriorityQueue\u003c\u003e(readerMap.size(), (a, b) -\u003e Long.compare(b.ramBytesUsed.get(), a.ramBytesUsed.get()));\n               synchronized (this) {\n                 for (ReadersAndUpdates rld : readerMap.values()) {\n                   queue.add(rld);\n                 }\n               }\n \n               int count \u003d 0;\n               while (ramBytesUsed \u003e 0.5 * mb * 1024 * 1024) {\n                 ReadersAndUpdates rld \u003d queue.poll();\n                 if (rld \u003d\u003d null) {\n                   break;\n                 }\n \n                 // We need to do before/after because not all RAM in this RAU is used by DV updates, and\n                 // not all of those bytes can be written here:\n                 long bytesUsedBefore \u003d rld.ramBytesUsed.get();\n \n                 // Only acquire IW lock on each write, since this is a time consuming operation.  This way\n                 // other threads get a chance to run in between our writes.\n                 synchronized (IndexWriter.this) {\n-                  rld.writeFieldUpdates(directory, bufferedUpdatesStream.getCompletedDelGen(), infoStream);\n+                  if (rld.writeFieldUpdates(directory, globalFieldNumberMap, bufferedUpdatesStream.getCompletedDelGen(), infoStream)) {\n+                    checkpointNoSIS();\n+                  }\n                 }\n                 long bytesUsedAfter \u003d rld.ramBytesUsed.get();\n                 ramBytesUsed -\u003d bytesUsedBefore - bytesUsedAfter;\n                 count++;\n               }\n \n               if (infoStream.isEnabled(\"BD\")) {\n                 infoStream.message(\"BD\", String.format(Locale.ROOT, \"done write some DV updates for %d segments: now %.2f MB used vs IWC Buffer %.2f MB; took %.2f sec\",\n                                                        count, ramBytesUsed()/1024./1024., mb, ((System.nanoTime() - startNS)/1000000000.)));\n               }\n             }\n           }\n         } finally {\n           writeDocValuesLock.set(false);\n         }\n       }\n     }\n\\ No newline at end of file\n",
      "extendedDetails": {}
    },
    "58105a203a19d18a56e09cf69dc0083c1b890315": {
      "type": "Yintroduced",
      "commitMessage": "LUCENE-7868: use multiple threads to concurrently resolve deletes and DV udpates\n",
      "commitDate": "2017-06-21, 1:47 p.m.",
      "commitName": "58105a203a19d18a56e09cf69dc0083c1b890315",
      "commitAuthor": "Mike McCandless",
      "diff": "@@ -0,0 +1,60 @@\n+    void writeSomeDocValuesUpdates() throws IOException {\n+\n+      assert Thread.holdsLock(IndexWriter.this) \u003d\u003d false;\n+\n+      if (writeDocValuesLock.compareAndSet(false, true)) {\n+        try {\n+\n+          LiveIndexWriterConfig config \u003d getConfig();\n+          double mb \u003d config.getRAMBufferSizeMB();\n+          // If the reader pool is \u003e 50% of our IW buffer, then write the updates:\n+          if (mb !\u003d IndexWriterConfig.DISABLE_AUTO_FLUSH) {\n+            long startNS \u003d System.nanoTime();\n+            \n+            long ramBytesUsed \u003d ramBytesUsed();\n+            if (ramBytesUsed \u003e 0.5 * mb * 1024 * 1024) {\n+              if (infoStream.isEnabled(\"BD\")) {\n+                infoStream.message(\"BD\", String.format(Locale.ROOT, \"now write some pending DV updates: %.2f MB used vs IWC Buffer %.2f MB\",\n+                                                       ramBytesUsed/1024./1024., mb));\n+              }\n+          \n+              // Sort by largest ramBytesUsed:\n+              PriorityQueue\u003cReadersAndUpdates\u003e queue \u003d new PriorityQueue\u003c\u003e(readerMap.size(), (a, b) -\u003e Long.compare(b.ramBytesUsed.get(), a.ramBytesUsed.get()));\n+              synchronized (this) {\n+                for (ReadersAndUpdates rld : readerMap.values()) {\n+                  queue.add(rld);\n+                }\n+              }\n+\n+              int count \u003d 0;\n+              while (ramBytesUsed \u003e 0.5 * mb * 1024 * 1024) {\n+                ReadersAndUpdates rld \u003d queue.poll();\n+                if (rld \u003d\u003d null) {\n+                  break;\n+                }\n+\n+                // We need to do before/after because not all RAM in this RAU is used by DV updates, and\n+                // not all of those bytes can be written here:\n+                long bytesUsedBefore \u003d rld.ramBytesUsed.get();\n+\n+                // Only acquire IW lock on each write, since this is a time consuming operation.  This way\n+                // other threads get a chance to run in between our writes.\n+                synchronized (IndexWriter.this) {\n+                  rld.writeFieldUpdates(directory, bufferedUpdatesStream.getCompletedDelGen(), infoStream);\n+                }\n+                long bytesUsedAfter \u003d rld.ramBytesUsed.get();\n+                ramBytesUsed -\u003d bytesUsedBefore - bytesUsedAfter;\n+                count++;\n+              }\n+\n+              if (infoStream.isEnabled(\"BD\")) {\n+                infoStream.message(\"BD\", String.format(Locale.ROOT, \"done write some DV updates for %d segments: now %.2f MB used vs IWC Buffer %.2f MB; took %.2f sec\",\n+                                                       count, ramBytesUsed()/1024./1024., mb, ((System.nanoTime() - startNS)/1000000000.)));\n+              }\n+            }\n+          }\n+        } finally {\n+          writeDocValuesLock.set(false);\n+        }\n+      }\n+    }\n\\ No newline at end of file\n",
      "actualSource": "    void writeSomeDocValuesUpdates() throws IOException {\n\n      assert Thread.holdsLock(IndexWriter.this) \u003d\u003d false;\n\n      if (writeDocValuesLock.compareAndSet(false, true)) {\n        try {\n\n          LiveIndexWriterConfig config \u003d getConfig();\n          double mb \u003d config.getRAMBufferSizeMB();\n          // If the reader pool is \u003e 50% of our IW buffer, then write the updates:\n          if (mb !\u003d IndexWriterConfig.DISABLE_AUTO_FLUSH) {\n            long startNS \u003d System.nanoTime();\n            \n            long ramBytesUsed \u003d ramBytesUsed();\n            if (ramBytesUsed \u003e 0.5 * mb * 1024 * 1024) {\n              if (infoStream.isEnabled(\"BD\")) {\n                infoStream.message(\"BD\", String.format(Locale.ROOT, \"now write some pending DV updates: %.2f MB used vs IWC Buffer %.2f MB\",\n                                                       ramBytesUsed/1024./1024., mb));\n              }\n          \n              // Sort by largest ramBytesUsed:\n              PriorityQueue\u003cReadersAndUpdates\u003e queue \u003d new PriorityQueue\u003c\u003e(readerMap.size(), (a, b) -\u003e Long.compare(b.ramBytesUsed.get(), a.ramBytesUsed.get()));\n              synchronized (this) {\n                for (ReadersAndUpdates rld : readerMap.values()) {\n                  queue.add(rld);\n                }\n              }\n\n              int count \u003d 0;\n              while (ramBytesUsed \u003e 0.5 * mb * 1024 * 1024) {\n                ReadersAndUpdates rld \u003d queue.poll();\n                if (rld \u003d\u003d null) {\n                  break;\n                }\n\n                // We need to do before/after because not all RAM in this RAU is used by DV updates, and\n                // not all of those bytes can be written here:\n                long bytesUsedBefore \u003d rld.ramBytesUsed.get();\n\n                // Only acquire IW lock on each write, since this is a time consuming operation.  This way\n                // other threads get a chance to run in between our writes.\n                synchronized (IndexWriter.this) {\n                  rld.writeFieldUpdates(directory, bufferedUpdatesStream.getCompletedDelGen(), infoStream);\n                }\n                long bytesUsedAfter \u003d rld.ramBytesUsed.get();\n                ramBytesUsed -\u003d bytesUsedBefore - bytesUsedAfter;\n                count++;\n              }\n\n              if (infoStream.isEnabled(\"BD\")) {\n                infoStream.message(\"BD\", String.format(Locale.ROOT, \"done write some DV updates for %d segments: now %.2f MB used vs IWC Buffer %.2f MB; took %.2f sec\",\n                                                       count, ramBytesUsed()/1024./1024., mb, ((System.nanoTime() - startNS)/1000000000.)));\n              }\n            }\n          }\n        } finally {\n          writeDocValuesLock.set(false);\n        }\n      }\n    }",
      "path": "lucene/core/src/java/org/apache/lucene/index/IndexWriter.java",
      "functionStartLine": 660,
      "functionName": "writeSomeDocValuesUpdates"
    }
  }
}